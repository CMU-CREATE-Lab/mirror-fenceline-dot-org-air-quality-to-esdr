{
 "metadata": {
  "name": "",
  "signature": "sha256:ebf6b3e91ad17313fcba45b04982e493c3c2ec256be67af8d7d788827be2b6be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime, dateutil, glob, re, time, urllib2\n",
      "from dateutil import parser, rrule, tz\n",
      "\n",
      "# scrapy web scraper\n",
      "# To install, run\n",
      "# !pip install scrapy\n",
      "# then restart kernel\n",
      "# If you see an error about zope version, double-check that you restarted the kernel\n",
      "from scrapy.selector import Selector\n",
      "\n",
      "def exec_ipynb(url):\n",
      "    import json, re, urllib2\n",
      "    nb = (urllib2.urlopen(url) if re.match(r'https?:', url) else open(url)).read()\n",
      "    exec '\\n'.join([''.join(cell['input']) for cell in json.loads(nb)['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
      "\n",
      "exec_ipynb('python-utils/esdr-library.ipynb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First time uploading, create a new client like so:\n",
      "\n",
      "# Esdr.save_client('esdr-auth-fenceline-uploader.json', 'fenceline.org uploader for timemachine1')\n",
      "\n",
      "# and then follow the directions it prints, which include visiting esdr.cmucreatelab.org and creating\n",
      "# a client with given parameters, and also editing esdr-auth-baaqm-uploader.json to include your\n",
      "# username and password\n",
      "\n",
      "# Do not add esdr-auth-baaqm-uploader.json to the git repo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "esdr = Esdr('esdr-auth-fenceline-uploader.json')\n",
      "product = esdr.get_or_create_product('fenceline_org', 'fenceline_org', 'Sensor networks run fenceline.org')\n",
      "product"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 166,
       "text": [
        "{u'created': u'2015-05-30T12:00:35.000Z',\n",
        " u'creatorUserId': 3,\n",
        " u'defaultChannelSpecs': {},\n",
        " u'description': u'Sensor networks run fenceline.org',\n",
        " u'id': 36,\n",
        " u'modified': u'2015-05-30T12:00:35.000Z',\n",
        " u'name': u'fenceline_org',\n",
        " u'prettyName': u'fenceline_org',\n",
        " u'vendor': u'fenceline_org'}"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def makeIdentifier(prettyName):\n",
      "    return re.sub('\\W+', '_', prettyName).strip('_')\n",
      "\n",
      "def tableToArray(sel):\n",
      "    ret = []\n",
      "    rows = sel.xpath('tr')\n",
      "    for row in rows:\n",
      "        cols = row.xpath('td')\n",
      "        rowText = []\n",
      "        for col in cols:\n",
      "            text = ' '.join(col.xpath('.//text()[not(ancestor::script)]').extract())\n",
      "            val = re.sub(r'\\s+', ' ', text).strip()\n",
      "            rowText.append(val)\n",
      "        ret.append(rowText)\n",
      "    return ret\n",
      "\n",
      "def fetchTable(selector, title):\n",
      "    # Find table with title in <thead>\n",
      "    table = tableToArray(selector.xpath(\"//table[thead[contains(.,'%s')]]\" % title))\n",
      "    return table\n",
      "\n",
      "# Convert to float, if possible\n",
      "def tryConvertToFloat(datum):\n",
      "    try:\n",
      "        return float(datum)\n",
      "    except:\n",
      "        return datum  \n",
      "    \n",
      "def parseColumn(table, col, columnPrefix=None):\n",
      "    date = None\n",
      "    time = None\n",
      "    channels = []\n",
      "    data = []\n",
      "    offline = False\n",
      "    for row in table[1:]:\n",
      "        if len(row) <= col:\n",
      "            continue\n",
      "        if row[0] == 'Date' or row[0] == 'Data Date':\n",
      "            date = row[col]\n",
      "        elif row[0] == 'Time' or row[0] == 'Data Time':\n",
      "            time = row[col]\n",
      "        else:\n",
      "            channel = makeIdentifier(row[0])\n",
      "            if columnPrefix != None:\n",
      "                channel = columnPrefix + '_' + channel\n",
      "            channels.append(channel)\n",
      "            datum = tryConvertToFloat(row[col])\n",
      "            if datum == 'ND':\n",
      "                datum = 0\n",
      "            elif datum == 'Offline':\n",
      "                return {'channel_names':[], 'data':[]}\n",
      "            data.append(datum)\n",
      "\n",
      "    timezone = tz.gettz('America/Los_Angeles')\n",
      "    timestamp = datetime.datetime.strptime(date + ' ' + time,'%Y-%m-%d %H:%M:%S').replace(tzinfo = timezone)\n",
      "    epoch_timestamp = (timestamp - datetime.datetime(1970, 1, 1, tzinfo=tz.tzutc())).total_seconds()\n",
      "    return {\n",
      "        'channel_names': channels,\n",
      "        'data': [[epoch_timestamp] + data]\n",
      "    }   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getStationFeed(name):\n",
      "    stationId = makeIdentifier(name)\n",
      "    device = esdr.get_device_by_serial_number(product, stationId)\n",
      "    if not device:\n",
      "        esdr.create_device(product, stationId, name=name)\n",
      "        device = esdr.get_device_by_serial_number(product, stationId)\n",
      "\n",
      "    feed = esdr.get_feed(device)\n",
      "    if not feed:\n",
      "        esdr.create_feed(device)\n",
      "        feed = esdr.get_feed(device)\n",
      "    return feed\n",
      "\n",
      "def upload(site, html):\n",
      "    if site == 'rodeo':\n",
      "        uploadRodeo(html)\n",
      "    elif site == 'richmond':\n",
      "        uploadRichmond(html)\n",
      "    else:\n",
      "        raise Exception('unknown site')\n",
      "\n",
      "def uploadRodeo(html):\n",
      "    selector = Selector(text = html)\n",
      "    \n",
      "    # Fence lines\n",
      "    for (feed_name, column) in [('Rodeo South Fenceline', 1), ('Rodeo North Fenceline', 2)]:\n",
      "        upload = []\n",
      "        for sensor in ['FTIR', 'UV', 'TDL']:\n",
      "            table = fetchTable(selector, sensor)\n",
      "            upload.append(parseColumn(table, column, sensor))\n",
      "        feed = getStationFeed(feed_name)\n",
      "        print 'Uploading to %s' % (feed_name)\n",
      "        esdr.upload(feed, upload)\n",
      "\n",
      "    # OGDs and Weather\n",
      "    ogd = fetchTable(selector, 'OGD')\n",
      "    ogdUpload = parseColumn(ogd, 1, 'OGD')\n",
      "\n",
      "    weather = fetchTable(selector, 'Weather')\n",
      "    weatherUpload = parseColumn(weather, 1, None)\n",
      "\n",
      "    # Extract wind direction\n",
      "    for row in weather:\n",
      "        for col in row:\n",
      "            for match in re.finditer(r'Wind is.*?(\\d+)', col):\n",
      "                weatherUpload['channel_names'].append('Wind_Direction')\n",
      "                weatherUpload['data'][0].append(float(match.group(1)))\n",
      "\n",
      "    upload = [ogdUpload, weatherUpload]\n",
      "    \n",
      "    feed = getStationFeed('Rodeo')\n",
      "\n",
      "    print 'Uploading to Rodeo'\n",
      "    esdr.upload(feed, upload)\n",
      "\n",
      "def uploadRichmond(html):\n",
      "    selector = Selector(text = html)\n",
      "\n",
      "    timestampText = re.search(r'System Status as of\\s+(\\w+\\s+.*?(am|pm))', html).group(1)\n",
      "    timestamp = dateutil.parser.parse(timestampText).replace(tzinfo=tz.gettz('America/Los_Angeles'))\n",
      "    epochTimestamp = (timestamp - datetime.datetime(1970, 1, 1, tzinfo=tz.tzutc())).total_seconds()\n",
      "    epochTimestamp\n",
      "\n",
      "    s = selector.xpath(\"//div[h3/text()[contains(.,'Atchison Village Area')]]\")\n",
      "    # Capture 6 tables, two for each site (fenceline and community)\n",
      "    tables = s.xpath(\".//table[.//text()[contains(.,'Chemical')]]\")\n",
      "    if len(tables) != 6:\n",
      "        raise Exception('Should have found 6 tables')\n",
      "    # Capture 3 site names\n",
      "    sites = s.xpath(\".//h3/text()\").extract()\n",
      "    if len(sites) != 3:\n",
      "        raise Exception('Should have found 3 sites')\n",
      "\n",
      "    for i in range(0, 6):\n",
      "        table = tables[i]\n",
      "        site_name = sites[i / 2].replace('Area', '')\n",
      "        site_name += ['Refinery Fence Line', 'Community'][i % 2]\n",
      "        feed = getStationFeed(site_name)\n",
      "        \n",
      "        \n",
      "        t = tableToArray(table)\n",
      "        upload = {'channel_names':[], 'data':[[epochTimestamp]]}\n",
      "\n",
      "        for row in t:\n",
      "            datum = tryConvertToFloat(re.sub(r'\\s*\\(.*?\\)', '', row[1]))\n",
      "            if datum == 'Nothing detected':\n",
      "                datum = 0\n",
      "            elif datum == 'Offline':\n",
      "                next\n",
      "            upload['channel_names'].append(makeIdentifier(row[0]))\n",
      "            upload['data'][0].append(datum)\n",
      "\n",
      "        # Skies\n",
      "        upload['channel_names'].append('Skies')\n",
      "        upload['data'][0].append(t[0][2])\n",
      "\n",
      "        # Weather\n",
      "        for row in t:\n",
      "            for field in row[2:]:\n",
      "                split = field.split(':')\n",
      "                if len(split) == 2:\n",
      "                    key = makeIdentifier(split[0])\n",
      "                    value = tryConvertToFloat(split[1])\n",
      "                    if key == 'Dew_Point' or key == 'Wind_Origin':\n",
      "                        continue\n",
      "                    upload['channel_names'].append(key)\n",
      "                    upload['data'][0].append(value)\n",
      "\n",
      "        esdr.upload(feed, upload)\n",
      "        print upload"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def uploadDate(date):\n",
      "    for site in ['rodeo', 'richmond']:\n",
      "        files = glob.glob('%s/%s/*.html' % (site, date.strftime('%Y-%m-%d')))\n",
      "\n",
      "        for file in files:\n",
      "            donePath = file + '.done'\n",
      "\n",
      "            if not os.path.exists(donePath):\n",
      "                print 'Want to upload %s' % file\n",
      "                html = open(file).read()\n",
      "                upload(site, html)\n",
      "                open(donePath, 'w')\n",
      "\n",
      "# Upload previous 2 weeks\n",
      "\n",
      "date = datetime.datetime(2015, 5, 29)\n",
      "\n",
      "for date in rrule.rrule(rrule.DAILY, datetime.date.today() - datetime.timedelta(days=14), until=datetime.date.today()):\n",
      "    uploadDate(date)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    }
   ],
   "metadata": {}
  }
 ]
}